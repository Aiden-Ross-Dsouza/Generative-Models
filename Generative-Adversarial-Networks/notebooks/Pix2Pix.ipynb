{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNl2K43+UgvuHszu0ODXAcE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aiden-Ross-Dsouza/Generative-Models/blob/main/Generative-Adversarial-Networks/notebooks/Pix2Pix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S6Ql5ZK2ZJXj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discriminator"
      ],
      "metadata": {
        "id": "wRn1gAYFXvL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNBlock(nn.Module):\n",
        "  def __init__(self, in_chans, out_chans, stride=2):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "      nn.Conv2d(in_chans, out_chans, 4, stride, bias=False, padding=1, padding_mode=\"reflect\"),\n",
        "      nn.InstanceNorm2d(out_chans, affine=True),\n",
        "      nn.LeakyReLU(0.2),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)"
      ],
      "metadata": {
        "id": "HdDnXVRabX0V"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, in_chans=3, features=[64, 128, 256, 512]):\n",
        "    super().__init__()\n",
        "    self.initial = nn.Sequential(\n",
        "        nn.Conv2d(in_chans*2, features[0], kernel_size=4, stride=2, padding=1, padding_mode=\"reflect\"),\n",
        "        nn.LeakyReLU(0.2),\n",
        "    )\n",
        "    layers = []\n",
        "    in_chans = features[0]\n",
        "    for feature in features[1:]:\n",
        "      layers.append(\n",
        "          CNNBlock(in_chans, feature, stride=1 if feature==features[-1] else 2)\n",
        "      )\n",
        "      in_chans = feature\n",
        "    layers.append(\n",
        "        nn.Conv2d(in_chans, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\")\n",
        "    )\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    x = torch.cat((x, y), dim=1)\n",
        "    x = self.initial(x)\n",
        "    return self.model(x)"
      ],
      "metadata": {
        "id": "dYmaSOxubWdJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  x = torch.randn((1, 3, 256, 256)) # (batch_dim, chan, img_dim, img_dim)\n",
        "  y = torch.randn((1, 3, 256, 256))\n",
        "  model = Discriminator()\n",
        "  preds = model(x,y)\n",
        "  print(preds.shape)\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4t0OTXYgyOW",
        "outputId": "f4e89937-df4f-439d-d7c5-f1bf13831197"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 30, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generator"
      ],
      "metadata": {
        "id": "dU_35DiWX0Aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "  def __init__(self, in_chans, out_chans, down=True, act=\"relu\", use_dropout=False):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_chans, out_chans, 4, 2, 1, bias=False, padding_mode=\"reflect\")\n",
        "        if down\n",
        "        else nn.ConvTranspose2d(in_chans, out_chans, 4, 2, 1, bias=False),\n",
        "        nn.InstanceNorm2d(out_chans, affine=True),\n",
        "        nn.ReLU() if act==\"relu\" else nn.LeakyReLU(0.2),\n",
        "    )\n",
        "    self.use_dropout = use_dropout\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    return self.dropout(x) if self.use_dropout else x"
      ],
      "metadata": {
        "id": "VmynhXLDhLgv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, in_chans=3, features=64):\n",
        "    super().__init__()\n",
        "    self.initial_down = nn.Sequential(\n",
        "        nn.Conv2d(in_chans, features, 4, 2, 1, padding_mode=\"reflect\"), # 256 -> 128\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "    self.down1 = Block(features, features*2, down=True, act=\"leaky\", use_dropout=False) # 128 -> 64\n",
        "    self.down2 = Block(features*2, features*4, down=True, act=\"leaky\", use_dropout=False) # 64 -> 32\n",
        "    self.down3 = Block(features*4, features*8, down=True, act=\"leaky\", use_dropout=False) # 32 -> 16\n",
        "    self.down4 = Block(features*8, features*8, down=True, act=\"leaky\", use_dropout=False) # 16 -> 8\n",
        "    self.down5 = Block(features*8, features*8, down=True, act=\"leaky\", use_dropout=False) # 8 -> 4\n",
        "    self.down6 = Block(features*8, features*8, down=True, act=\"leaky\", use_dropout=False) # 4 -> 2\n",
        "    self.bottleneck = nn.Sequential(\n",
        "        nn.Conv2d(features*8, features*8, 4, 2, 1, padding_mode=\"reflect\"), # 2 -> 1\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.up1 = Block(features*8, features*8, down=False, act=\"relu\", use_dropout=True)\n",
        "    self.up2 = Block(features*8*2, features*8, down=False, act=\"relu\", use_dropout=True)\n",
        "    self.up3 = Block(features*8*2, features*8, down=False, act=\"relu\", use_dropout=True)\n",
        "    self.up4 = Block(features*8*2, features*8, down=False, act=\"relu\", use_dropout=False)\n",
        "    self.up5 = Block(features*8*2, features*4, down=False, act=\"relu\", use_dropout=False)\n",
        "    self.up6 = Block(features*4*2, features*2, down=False, act=\"relu\", use_dropout=False)\n",
        "    self.up7 = Block(features*2*2, features, down=False, act=\"relu\", use_dropout=False)\n",
        "    self.final_up = nn.Sequential(\n",
        "        nn.ConvTranspose2d(features*2, in_chans, 4, 2, 1),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    d1 = self.initial_down(x)\n",
        "    d2 = self.down1(d1)\n",
        "    d3 = self.down2(d2)\n",
        "    d4 = self.down3(d3)\n",
        "    d5 = self.down4(d4)\n",
        "    d6 = self.down5(d5)\n",
        "    d7 = self.down6(d6)\n",
        "    bottleneck = self.bottleneck(d7)\n",
        "    up1 = self.up1(bottleneck)\n",
        "    up2 = self.up2(torch.cat([up1, d7], 1))\n",
        "    up3 = self.up3(torch.cat([up2, d6], 1))\n",
        "    up4 = self.up4(torch.cat([up3, d5], 1))\n",
        "    up5 = self.up5(torch.cat([up4, d4], 1))\n",
        "    up6 = self.up6(torch.cat([up5, d3], 1))\n",
        "    up7 = self.up7(torch.cat([up6, d2], 1))\n",
        "    return self.final_up(torch.cat([up7, d1], 1))"
      ],
      "metadata": {
        "id": "Dxv6YE7ca_vA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  x = torch.randn((1, 3, 256, 256))\n",
        "  model = Generator(in_chans=3, features=64)\n",
        "  preds = model(x)\n",
        "  print(preds.shape)\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqa0Xs1Ks4BN",
        "outputId": "5bcc17d7-3923-4f91-bdf6-af38121de43c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "id": "PosZsLyPa7x-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2"
      ],
      "metadata": {
        "id": "dTB_lF6cXBbT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6f9e6e3-2365-43d3-d2fd-b04e5566d06e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.7' (you have '2.0.6'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "lr = 2e-4\n",
        "batch_size = 16\n",
        "num_workers = 2\n",
        "img_size = 256\n",
        "chans_img = 3\n",
        "l1_lambda = 100\n",
        "num_epochs = 100\n",
        "load_model = False\n",
        "save_model = True\n",
        "checkpoint_disc = \"/content/drive/MyDrive/Pix2PixGAN_results/disc.pth.tar\"\n",
        "checkpoint_gen = \"/content/drive/MyDrive/Pix2PixGAN_results/gen.pth.tar\""
      ],
      "metadata": {
        "id": "L38ejAlsbMb7"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "both_transform = A.Compose(\n",
        "    [A.Resize(width=256, height=256)], additional_targets={\"image0\": \"image\"},\n",
        ")\n",
        "\n",
        "transform_only_input = A.Compose(\n",
        "    [\n",
        "        A.ColorJitter(p=0.1),\n",
        "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255.0),\n",
        "        ToTensorV2()\n",
        "    ]\n",
        ")\n",
        "\n",
        "transform_only_mask = A.Compose(\n",
        "    [\n",
        "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255.0),\n",
        "        ToTensorV2()\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "byxsoWE8dqGH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "MkjKFL6-WyUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "8llu61i4jYJM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MapDataset(Dataset):\n",
        "  def __init__(self, root_dir):\n",
        "    super().__init__()\n",
        "    self.root_dir = root_dir\n",
        "    self.list_files = os.listdir(self.root_dir)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.list_files)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_file = self.list_files[idx]\n",
        "    img_path = os.path.join(self.root_dir, img_file)\n",
        "    image = np.array(Image.open(img_path))\n",
        "    input_image = image[:, : image.shape[1]//2, :]\n",
        "    target_image = image[:, image.shape[1]//2: , :]\n",
        "\n",
        "    augmentations = both_transform(image=input_image, image0=target_image)\n",
        "    input_image, target_image = augmentations[\"image\"], augmentations[\"image0\"]\n",
        "\n",
        "    input_image = transform_only_input(image=input_image)[\"image\"]\n",
        "    target_image = transform_only_mask(image=target_image)[\"image\"]\n",
        "\n",
        "    return input_image, target_image"
      ],
      "metadata": {
        "id": "RHlOAIy9tPSQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "cskjKUSNi5xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from torchvision.utils import save_image"
      ],
      "metadata": {
        "id": "h3213YByjA33"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_some_examples(gen, val_loader, epoch, folder):\n",
        "    x, y = next(iter(val_loader))\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    gen.eval()\n",
        "    with torch.no_grad():\n",
        "        y_fake = gen(x)\n",
        "        y_fake = y_fake * 0.5 + 0.5  # remove normalization#\n",
        "        save_image(y_fake, folder + f\"/y_gen_{epoch}.png\")\n",
        "        save_image(x * 0.5 + 0.5, folder + f\"/input_{epoch}.png\")\n",
        "        if epoch == 1:\n",
        "            save_image(y * 0.5 + 0.5, folder + f\"/label_{epoch}.png\")\n",
        "    gen.train()"
      ],
      "metadata": {
        "id": "_u3uZlexjKXP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, filename)"
      ],
      "metadata": {
        "id": "s4J4JgFxjNeN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "    # If we don't do this then it will just have learning rate of old checkpoint\n",
        "    # and it will lead to many hours of debugging \\:\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr"
      ],
      "metadata": {
        "id": "IcpqVdnAi4zi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "L_7prIztjN4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "RNEJuaAoa68D"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(disc, gen, train_loader, opt_disc, opt_gen, L1_loss, BCE, g_scaler, d_scaler):\n",
        "\n",
        "  for idx, (x, y) in enumerate(tqdm(train_loader, leave=True)):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "\n",
        "    # train discriminator\n",
        "    with torch.cuda.amp.autocast():\n",
        "      y_fake = gen(x)\n",
        "      D_real = disc(x, y)\n",
        "      D_fake = disc(x, y_fake.detach())\n",
        "      D_real_loss = BCE(D_real, torch.ones_like(D_real))\n",
        "      D_fake_loss = BCE(D_fake, torch.zeros_like(D_fake))\n",
        "      D_loss = (D_real_loss + D_fake_loss) / 2\n",
        "\n",
        "    opt_disc.zero_grad()\n",
        "    d_scaler.scale(D_loss).backward()\n",
        "    d_scaler.step(opt_disc)\n",
        "    d_scaler.update()\n",
        "\n",
        "    #train generator\n",
        "    with torch.cuda.amp.autocast():\n",
        "      D_fake = disc(x, y_fake)\n",
        "      G_fake_loss = BCE(D_fake, torch.ones_like(D_fake))\n",
        "      L1 = L1_loss(y_fake, y) * l1_lambda\n",
        "      G_loss = G_fake_loss + L1\n",
        "\n",
        "    opt_gen.zero_grad()\n",
        "    g_scaler.scale(G_loss).backward()\n",
        "    g_scaler.step(opt_gen)\n",
        "    g_scaler.update()"
      ],
      "metadata": {
        "id": "-ORdWPUimTOd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Dataset"
      ],
      "metadata": {
        "id": "Hmji03Hbn633"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "xXjiikhXl7pC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx8JHYCbmpaO",
        "outputId": "aeeb5c5d-769d-4246-81ab-ac5ea1ba3d2b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Kaggle directory\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "\n",
        "# Define source and destination paths\n",
        "source = \"/content/drive/MyDrive/Kaggle_API/kaggle.json\"\n",
        "destination = \"/root/.kaggle/kaggle.json\"\n",
        "\n",
        "# Copy the file\n",
        "shutil.copy(source, destination)\n",
        "\n",
        "# Set correct permissions\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "V8WHBPsPlzTq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d alincijov/pix2pix-maps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oiIfeFOl_6g",
        "outputId": "33974bea-c52f-4045-b926-ef1e832f0ba8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/alincijov/pix2pix-maps\n",
            "License(s): CC0-1.0\n",
            "Downloading pix2pix-maps.zip to /content\n",
            " 80% 192M/239M [00:00<00:00, 673MB/s]  \n",
            "100% 239M/239M [00:00<00:00, 657MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the dataset\n",
        "with zipfile.ZipFile(\"pix2pix-maps.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"pix2pix-maps\")\n",
        "\n",
        "# List extracted files\n",
        "!ls pix2pix-maps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VMYT3KjmCCo",
        "outputId": "47229e44-8328-4223-b7f3-77b711ebb859"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train  val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "6DBTYjORl5Qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  disc = Discriminator(in_chans=3).to(device)\n",
        "  gen = Generator(in_chans=3).to(device)\n",
        "  opt_disc = optim.Adam(disc.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "  opt_gen = optim.Adam(gen.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "  BCE = nn.BCEWithLogitsLoss()\n",
        "  l1_loss = nn.L1Loss()\n",
        "\n",
        "  if load_model:\n",
        "    load_checkpoint(checkpoint_gen, gen, opt_gen, lr)\n",
        "    load_checkpoint(checkpoint_disc, disc, opt_disc, lr)\n",
        "\n",
        "  train_dataset = MapDataset(root_dir=\"pix2pix-maps/train\")\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "  g_scaler = torch.cuda.amp.GradScaler()\n",
        "  d_scaler = torch.cuda.amp.GradScaler()\n",
        "  val_dataset = MapDataset(root_dir='pix2pix-maps/val')\n",
        "  val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    train(disc, gen, train_loader, opt_disc, opt_gen, l1_loss, BCE, g_scaler, d_scaler)\n",
        "    if save_model and epoch % 5 == 0:\n",
        "      save_checkpoint(gen, opt_gen, filename=checkpoint_gen)\n",
        "      save_checkpoint(disc, opt_disc, filename=checkpoint_disc)\n",
        "\n",
        "    save_some_examples(gen, val_loader, epoch, folder='/content/drive/MyDrive/Pix2PixGAN_results')"
      ],
      "metadata": {
        "id": "YIQMh0d2ptmK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yThAd51th-80",
        "outputId": "97cfdbc0-3454-4746-c77e-1193dc90c0f1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-633651e47a7e>:15: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  g_scaler = torch.cuda.amp.GradScaler()\n",
            "<ipython-input-37-633651e47a7e>:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  d_scaler = torch.cuda.amp.GradScaler()\n",
            "  0%|          | 0/69 [00:00<?, ?it/s]<ipython-input-18-89f371f0055d>:7: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "<ipython-input-18-89f371f0055d>:21: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:14<00:00,  4.63it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.63it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.79it/s]\n",
            "100%|██████████| 69/69 [00:13<00:00,  4.96it/s]\n",
            "100%|██████████| 69/69 [00:13<00:00,  4.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:14<00:00,  4.65it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.67it/s]\n",
            "100%|██████████| 69/69 [00:15<00:00,  4.59it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.87it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:14<00:00,  4.69it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.70it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.70it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.68it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:14<00:00,  4.68it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.72it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.76it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.75it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:14<00:00,  4.74it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.70it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.73it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.75it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:15<00:00,  4.60it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.71it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.65it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.78it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:14<00:00,  4.68it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.70it/s]\n",
            "100%|██████████| 69/69 [00:15<00:00,  4.59it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.67it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:14<00:00,  4.60it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.65it/s]\n",
            "100%|██████████| 69/69 [00:15<00:00,  4.60it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.75it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:15<00:00,  4.52it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.78it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.61it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.65it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:14<00:00,  4.65it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.68it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.67it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.71it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:15<00:00,  4.59it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.60it/s]\n",
            "100%|██████████| 69/69 [00:15<00:00,  4.54it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.74it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:14<00:00,  4.77it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.74it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.67it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.85it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:14<00:00,  4.62it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.60it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.73it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.85it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:15<00:00,  4.53it/s]\n",
            "100%|██████████| 69/69 [00:15<00:00,  4.47it/s]\n",
            "100%|██████████| 69/69 [00:15<00:00,  4.56it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.78it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:14<00:00,  4.65it/s]\n",
            "100%|██████████| 69/69 [00:15<00:00,  4.56it/s]\n",
            "100%|██████████| 69/69 [00:15<00:00,  4.51it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.68it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:14<00:00,  4.65it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.64it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.64it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.85it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:14<00:00,  4.65it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.71it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.71it/s]\n",
            "100%|██████████| 69/69 [00:15<00:00,  4.57it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:15<00:00,  4.52it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.63it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.63it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.68it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:15<00:00,  4.55it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.66it/s]\n",
            "100%|██████████| 69/69 [00:15<00:00,  4.55it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.74it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [00:15<00:00,  4.55it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.68it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.70it/s]\n",
            "100%|██████████| 69/69 [00:14<00:00,  4.78it/s]\n"
          ]
        }
      ]
    }
  ]
}