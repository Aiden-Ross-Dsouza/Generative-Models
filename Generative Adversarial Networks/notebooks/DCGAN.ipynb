{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPw7f6osqLMOHmWi8S4+H/I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aiden-Ross-Dsouza/Generative-Models/blob/main/Generative%20Adversarial%20Networks/notebooks/DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Packages"
      ],
      "metadata": {
        "id": "My6gdDcahQCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch-fid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ynSC6gaLi-h",
        "outputId": "7c68eed7-87c3-4ac7-ba45-8b16ffd2ba1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-fid in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-fid) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pytorch-fid) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pytorch-fid) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-fid) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-fid) (0.19.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->pytorch-fid) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->pytorch-fid) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->pytorch-fid) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->pytorch-fid) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->pytorch-fid) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->pytorch-fid) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.1->pytorch-fid) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.1->pytorch-fid) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Liraries"
      ],
      "metadata": {
        "id": "ok3ymVV0TZ9O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8A4CLRGJp5Hv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discriminator"
      ],
      "metadata": {
        "id": "w1jgCQXxTue1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, channels_img, features_d):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            # Input: N X channels_img X 64 X 64\n",
        "            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1), # 32 X 32\n",
        "            nn.LeakyReLU(0.2),\n",
        "            self.block(features_d, features_d*2, 4, 2, 1), # 16 X 16\n",
        "            self.block(features_d*2, features_d*4, 4, 2, 1), # 8 X 8\n",
        "            self.block(features_d*4, features_d*8, 4, 2, 1), # 4 X 4\n",
        "            nn.Conv2d(features_d*8, 1, kernel_size=4, stride=2, padding=0), # 1 X 1\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        return nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
        "                             nn.BatchNorm2d(out_channels),\n",
        "                             nn.LeakyReLU(0.2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.disc(x)"
      ],
      "metadata": {
        "id": "VK8WaVAMTrdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generator"
      ],
      "metadata": {
        "id": "x79ommYWb-XK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, z_dim, channels_img, features_g):\n",
        "    super(Generator, self).__init__()\n",
        "    self.gen = nn.Sequential(\n",
        "        # Input: N X z_dim X 1 X 1\n",
        "        self.block(z_dim, features_g*16, 4, 1, 0), #N X f_g*16 X 4 X 4\n",
        "        self.block(features_g*16, features_g*8, 4, 2, 1), # 8 X 8\n",
        "        self.block(features_g*8, features_g*4, 4, 2, 1), # 16 X 16\n",
        "        self.block(features_g*4, features_g*2, 4, 2, 1), # 32 X 32\n",
        "        nn.ConvTranspose2d(features_g*2, channels_img, kernel_size=4, stride=2, padding=1), # 64 X 64\n",
        "        nn.Tanh(),\n",
        "    )\n",
        "\n",
        "  def block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "    return nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.gen(x)"
      ],
      "metadata": {
        "id": "jNrxwJ8NcFIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize weights"
      ],
      "metadata": {
        "id": "kW5sQdccQqL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(model):\n",
        "  for m in model.modules():\n",
        "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
        "      nn.init.normal_(m.weight.data, 0.0, 0.02)"
      ],
      "metadata": {
        "id": "GC7DzgMFQUlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "NzPOVBhCQxqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  N, in_channels, H, W = 8, 3, 64, 64\n",
        "  z_dim = 100\n",
        "  x = torch.randn((N, in_channels, H, W))\n",
        "  disc = Discriminator(in_channels, 8)\n",
        "  initialize_weights(disc)\n",
        "  assert disc(x).shape == (N, 1, 1, 1)\n",
        "  gen = Generator(z_dim, in_channels, 8)\n",
        "  initialize_weights(gen)\n",
        "  z = torch.randn((N, z_dim, 1, 1))\n",
        "  assert gen(z).shape == (N, in_channels, H, W)\n",
        "  print(\"Success\")"
      ],
      "metadata": {
        "id": "x-04fZZ3Q1yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Generated Images"
      ],
      "metadata": {
        "id": "pxw91JhmJKSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
        "    image_tensor = (image_tensor + 1) / 2  # De-normalize the images to [0, 1] range\n",
        "    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n",
        "    image_grid = torchvision.utils.make_grid(image_unflat[:num_images], nrow=5)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "OWVe-1iSJRIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Images"
      ],
      "metadata": {
        "id": "JbGe5d8DMgHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('generated_images', exist_ok=True)\n",
        "os.makedirs('real_images', exist_ok=True)\n",
        "\n",
        "def save_images(images, directory, prefix, num_images=25):\n",
        "    images = (images + 1) / 2  # De-normalize the images to [0, 1] range\n",
        "    image_grid = torchvision.utils.make_grid(images[:num_images], nrow=5)\n",
        "    image_grid = image_grid.permute(1, 2, 0).cpu().numpy() * 255\n",
        "    image_filename = os.path.join(directory, f\"{prefix}.png\")\n",
        "    plt.imsave(image_filename, image_grid.astype(np.uint8))"
      ],
      "metadata": {
        "id": "oPaQZYywMlp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "C9IGnVNdSbVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "lr = 2e-4\n",
        "batch_size = 128\n",
        "image_size = 64\n",
        "channels_img = 3\n",
        "z_dim = 100\n",
        "num_epochs = 5\n",
        "features_disc = 64\n",
        "features_gen = 64\n",
        "\n",
        "image_transforms = transforms.Compose(\n",
        "    [\n",
        "     transforms.Resize(image_size),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize([0.5 for _ in range(channels_img)], [0.5 for _ in range(channels_img)]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "dataset = datasets.CIFAR10(root = \"dataset/\", train=True, transform=image_transforms, download=True)\n",
        "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "gen = Generator(z_dim, channels_img, features_gen).to(device)\n",
        "disc = Discriminator(channels_img, features_disc).to(device)\n",
        "initialize_weights(gen)\n",
        "initialize_weights(disc)\n",
        "\n",
        "opt_gen = optim.Adam(gen.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "opt_disc = optim.Adam(disc.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "fixed_noise = torch.randn(32, z_dim, 1, 1).to(device)\n",
        "writer_real = SummaryWriter(f\"logs/real\")\n",
        "writer_fake = SummaryWriter(f\"logs/fake\")\n",
        "step = 0\n",
        "\n",
        "gen.train()\n",
        "disc.train()\n",
        "\n",
        "gen_losses = []\n",
        "disc_losses = []\n",
        "iterations = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for batch_idx, (real, _) in enumerate(loader):\n",
        "    real = real.to(device)\n",
        "    noise = torch.randn((batch_size, z_dim, 1, 1)).to(device)\n",
        "    fake = gen(noise)\n",
        "\n",
        "    # Train Discriminator max log(D(x)) + log(1-d(G(z)))\n",
        "    disc_real = disc(real).reshape(-1)\n",
        "    loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n",
        "    disc_fake = disc(fake).reshape(-1)\n",
        "    loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
        "    loss_disc = (loss_disc_real + loss_disc_fake) / 2\n",
        "    disc.zero_grad()\n",
        "    loss_disc.backward(retain_graph=True)\n",
        "    opt_disc.step()\n",
        "\n",
        "    #Train Generator min log(1-D(G(z))) <-> max log(D(G(Z)))\n",
        "    output = disc(fake).reshape(-1)\n",
        "    loss_gen = criterion(output, torch.ones_like(output))\n",
        "    gen.zero_grad()\n",
        "    loss_gen.backward()\n",
        "    opt_gen.step()\n",
        "\n",
        "    gen_losses.append(loss_gen.item())\n",
        "    disc_losses.append(loss_disc.item())\n",
        "    iterations.append(epoch * len(loader) + batch_idx)\n",
        "\n",
        "    #Print losses occassionally\n",
        "    if batch_idx % 100 == 0:\n",
        "      print(\n",
        "          f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\\n",
        "          Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\"\n",
        "      )\n",
        "\n",
        "      with torch.no_grad():\n",
        "        fake = gen(fixed_noise)\n",
        "        img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n",
        "        img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
        "\n",
        "        writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
        "        writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
        "\n",
        "        save_images(real.cpu(), 'real_images', f'real_epoch_{epoch}_batch_{batch_idx}')\n",
        "        save_images(fake.cpu(), 'generated_images', f'fake_epoch_{epoch}_batch_{batch_idx}')\n",
        "\n",
        "        show_tensor_images(fake, num_images=25, size=(channels_img, image_size, image_size))\n",
        "\n",
        "      step += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "ad8-cK7PSgKH",
        "outputId": "471dbc7b-1363-4a8b-c068-3dec855cfd8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-2480a38a73b7>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"dataset/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_transforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mdisc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannels_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_disc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0minitialize_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1172\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1158\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m                     )\n\u001b[0;32m-> 1160\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1161\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate Frechet Inception Distance"
      ],
      "metadata": {
        "id": "uzzZZlNdJhUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_fid(real_images_dir, fake_images_dir):\n",
        "    # Call the FID computation from the command line\n",
        "    result = subprocess.run([\n",
        "        'python', '-m', 'pytorch_fid', real_images_dir, fake_images_dir\n",
        "    ], capture_output=True, text=True)\n",
        "\n",
        "    # Parse and print FID score\n",
        "    fid_score_line = [line for line in result.stdout.split('\\n') if 'FID' in line]\n",
        "    if fid_score_line:\n",
        "        fid_score = fid_score_line[0].split()[-1]\n",
        "        print(f\"FID Score: {fid_score}\")\n",
        "\n",
        "# Call this function after training\n",
        "compute_fid('real_images', 'generated_images')\n"
      ],
      "metadata": {
        "id": "d0Fpch55MLfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Losses"
      ],
      "metadata": {
        "id": "uGN-XnZSKUlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(iterations, gen_losses, label='Generator Loss')\n",
        "plt.plot(iterations, disc_losses, label='Discriminator Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Generator and Discriminator Losses')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IVw-4wTaKZdW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}